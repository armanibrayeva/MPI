# -*- coding: utf-8 -*-
"""Emmi_Project_V1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dLmSn4VLDFQCJEKHpITn-AyPL4HXy2dd
"""

import torch
import os
from pathlib import Path

print("üî• GOOGLE COLAB STENOSIS DETECTION SETUP")
print("=" * 50)

# Check GPU availability
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    print(f"‚úÖ GPU Available: {gpu_name}")
    print(f"üî• Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    device = 'cuda'
else:
    print("‚ùå No GPU detected!")
    print("üîß Go to Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator: GPU")
    device = 'cpu'

print(f"‚ö° Using device: {device}")

# CELL 2: Install Requirements
# ==============================================================================

print("\nüì¶ INSTALLING REQUIREMENTS...")

# Install ultralytics (YOLO)
!pip install -q ultralytics

# Import required libraries
import cv2
import numpy as np
import matplotlib.pyplot as plt
from ultralytics import YOLO
import zipfile
import shutil
from datetime import datetime
import json

print("‚úÖ All packages installed!")

# CELL 3: Mount Google Drive and Upload Dataset


# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Cell 4

# Set your dataset path (modify this to match your folder structure)
DATASET_PATH = "/content/drive/MyDrive/Dataset1yolo8coco/stenosis"

# Let's first check what's inside your dataset folder
import os
from pathlib import Path

print("üìÅ Checking your dataset folder...")
base_path = "/content/drive/MyDrive/Datasettyolo8coco"

if os.path.exists(base_path):
    print(f"‚úÖ Found dataset folder: {base_path}")

    # List contents to see the structure
    contents = os.listdir(base_path)
    print("üìÇ Contents:", contents)

    # Check if there's a 'stenosis' subfolder or if the data is directly here
    if 'stenosis' in contents:
        DATASET_PATH = f"{base_path}/stenosis"
        print(f"‚úÖ Using path: {DATASET_PATH}")
    else:
        # Data might be directly in the main folder
        DATASET_PATH = base_path
        print(f"‚úÖ Using path: {DATASET_PATH}")
else:
    print("‚ùå Dataset folder not found!")

import os
from pathlib import Path

print("üîç Exploring your Google Drive...")

# Check if drive is mounted
drive_path = "/content/drive/MyDrive"
if os.path.exists(drive_path):
    print("‚úÖ Google Drive is mounted")

    # List all folders in your Drive
    folders = [f for f in os.listdir(drive_path) if os.path.isdir(os.path.join(drive_path, f))]
    print(f"\nüìÇ Folders in your Google Drive:")
    for i, folder in enumerate(folders, 1):
        print(f"   {i}. {folder}")

    # Look for dataset-related folders
    dataset_candidates = [f for f in folders if 'dataset' in f.lower() or 'yolo' in f.lower() or 'stenosis' in f.lower()]

    if dataset_candidates:
        print(f"\nüéØ Possible dataset folders:")
        for candidate in dataset_candidates:
            print(f"   üìÅ {candidate}")
            # Check what's inside
            candidate_path = os.path.join(drive_path, candidate)
            try:
                contents = os.listdir(candidate_path)
                print(f"      Contents: {contents[:5]}...")  # Show first 5 items
            except:
                print("      (Cannot read contents)")
    else:
        print("\n‚ö†Ô∏è No obvious dataset folders found")
        print("üìù All folders listed above - which one contains your stenosis dataset?")

else:
    print("‚ùå Google Drive not mounted!")
    print("üîß Run: from google.colab import drive; drive.mount('/content/drive')")

# Set the correct dataset path
DATASET_PATH = "/content/drive/MyDrive/Dataset1yolo8coco/stenosis"

print(f"üéØ Using dataset path: {DATASET_PATH}")

# Verify the stenosis folder structure
import os
from pathlib import Path

def verify_colab_dataset():
    dataset_base = Path(DATASET_PATH)

    if not dataset_base.exists():
        print(f"‚ùå Dataset not found at: {dataset_base}")
        return False

    print(f"üìä DATASET VERIFICATION:")
    print(f"üìÅ Base path: {dataset_base}")

    # First, let's see what's in the stenosis folder
    stenosis_contents = os.listdir(dataset_base)
    print(f"üìÇ Stenosis folder contents: {stenosis_contents}")

    total_images = 0

    for split in ['train', 'val', 'test']:
        images_dir = dataset_base / split / 'images'
        labels_dir = dataset_base / split / 'labels'

        print(f"\n--- Checking {split} split ---")
        print(f"Looking for images: {images_dir}")
        print(f"Looking for labels: {labels_dir}")

        if images_dir.exists() and labels_dir.exists():
            images = len(list(images_dir.glob('*.png')) + list(images_dir.glob('*.jpg')))
            labels = len(list(labels_dir.glob('*.txt')))
            total_images += images
            print(f"   ‚úÖ {split}: {images} images, {labels} labels")
        else:
            print(f"   ‚ùå {split}: Missing directories")
            # Check if the directories exist individually
            if images_dir.exists():
                print(f"      ‚úÖ Images dir exists")
            else:
                print(f"      ‚ùå Images dir missing")
            if labels_dir.exists():
                print(f"      ‚úÖ Labels dir exists")
            else:
                print(f"      ‚ùå Labels dir missing")

    print(f"\nüìà Total: {total_images} images")
    return total_images > 0

# Run verification
dataset_ready = verify_colab_dataset()

print("üì¶ Installing requirements...")
!pip install -q ultralytics

import torch
import cv2
import numpy as np
import matplotlib.pyplot as plt
from ultralytics import YOLO
from datetime import datetime

print("‚úÖ All packages installed!")

# Check GPU
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    print(f"‚úÖ GPU Available: {gpu_name}")
    device = 'cuda'
else:
    print("‚ùå No GPU detected!")
    print("üîß Go to Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator: GPU")
    device = 'cpu'

print(f"‚ö° Using device: {device}")

# Check if there's already a config file
config_path = "/content/drive/MyDrive/Dataset1yolo8coco/stenosis/data.yaml"

print("üìã Checking existing config...")
if os.path.exists(config_path):
    with open(config_path, 'r') as f:
        config_content = f.read()
    print("‚úÖ Found existing config:")
    print(config_content)
else:
    print("Creating new config...")
    config_content = f'''# Stenosis Detection Dataset
path: {DATASET_PATH}

train: train/images
val: val/images
test: test/images

# Classes
nc: 1
names:
  0: stenosis
'''

    with open(config_path, 'w') as f:
        f.write(config_content)
    print(f"‚úÖ Config created: {config_path}")

print(f"\nüöÄ Ready to train with config: {config_path}")

# from datetime import datetime

# # Training configuration optimized for your T4 GPU
# TRAINING_CONFIG = {
#     'model': 'yolov10n.pt',      # Nano model (fastest)
#     'epochs': 10,                # Quick training
#     'batch': 16,                 # Good for T4 GPU
#     'imgsz': 640,                # Standard resolution
#     'device': 'cuda',
#     'project': 'stenosis_colab',
#     'name': f'fast_training_{datetime.now().strftime("%H%M")}',
#     'patience': 5,
#     'save_period': 2,
#     'verbose': True,
#     'plots': True,
#     'val': True,
#     'cache': True,               # Cache for speed
#     'workers': 2,
#     'amp': True                  # Mixed precision for speed
# }

# print("üî• STARTING STENOSIS DETECTION TRAINING")
# print("=" * 50)
# print(f"üìä Dataset: {DATASET_PATH}")
# print(f"üñ•Ô∏è GPU: Tesla T4")
# print(f"‚è±Ô∏è Expected time: 5-10 minutes")
# print(f"üìà Training on 997 images, validating on 200")

# # Load model and start training
# print(f"\nü§ñ Loading {TRAINING_CONFIG['model']}...")
# model = YOLO(TRAINING_CONFIG['model'])

# print("üöÄ Training started...")
# start_time = datetime.now()

# # Start training
# results = model.train(
#     data=config_path,
#     epochs=TRAINING_CONFIG['epochs'],
#     batch=TRAINING_CONFIG['batch'],
#     imgsz=TRAINING_CONFIG['imgsz'],
#     device=TRAINING_CONFIG['device'],
#     project=TRAINING_CONFIG['project'],
#     name=TRAINING_CONFIG['name'],
#     patience=TRAINING_CONFIG['patience'],
#     save_period=TRAINING_CONFIG['save_period'],
#     verbose=TRAINING_CONFIG['verbose'],
#     plots=TRAINING_CONFIG['plots'],
#     val=TRAINING_CONFIG['val'],
#     cache=TRAINING_CONFIG['cache'],
#     workers=TRAINING_CONFIG['workers'],
#     amp=TRAINING_CONFIG['amp']
# )

# end_time = datetime.now()
# training_duration = (end_time - start_time).total_seconds() / 60

# print(f"\nüéâ TRAINING COMPLETED!")
# print(f"‚è±Ô∏è Training time: {training_duration:.1f} minutes")

# # Cell: Export Training Visualizations (Loss, mAP, Confusion Matrix)
# import os
# import matplotlib.pyplot as plt
# from PIL import Image
# from glob import glob

# # Set your project and experiment folder
# PROJECT_DIR = "/content/stenosis_colab"  # or "medical_stenosis"
# EXPERIMENT_NAME = "fast_training_0403"  # or "medical_training_XXXX"

# EXP_DIR = os.path.join(PROJECT_DIR, EXPERIMENT_NAME)
# assert os.path.exists(EXP_DIR), f"‚ùå Directory not found: {EXP_DIR}"

# # Search for standard YOLO plots
# plot_files = sorted(glob(os.path.join(EXP_DIR, "*.png")))
# print(f"üìä Found {len(plot_files)} plot(s) in {EXP_DIR}")

# # Display and optionally save all plots
# output_dir = "/content/training_plots"
# os.makedirs(output_dir, exist_ok=True)

# for pf in plot_files:
#     img = Image.open(pf)
#     plt.figure(figsize=(10, 6))
#     plt.imshow(img)
#     plt.axis('off')
#     plt.title(os.path.basename(pf))
#     plt.show()

#     # Save to exports
#     img.save(os.path.join(output_dir, os.path.basename(pf)))
#     print(f"‚úÖ Exported: {os.path.join(output_dir, os.path.basename(pf))}")

# print("üè• MEDICAL-GRADE STENOSIS DETECTION TRAINING")
# print("=" * 50)

# # Better training configuration for medical AI
# MEDICAL_CONFIG = {
#     'model': 'yolov10s.pt',      # Small model (better than nano)
#     'epochs': 100,               # Much longer training
#     'batch': 8,                  # Smaller batch for stability
#     'imgsz': 640,
#     'device': 'cuda',
#     'project': 'medical_stenosis',
#     'name': f'medical_training_{datetime.now().strftime("%H%M")}',
#     'patience': 20,              # More patience
#     'save_period': 10,
#     'verbose': True,
#     'plots': True,
#     'val': True,
#     'cache': 'disk',             # Disk cache for stability
#     'workers': 2,
#     'amp': True,
#     'lr0': 0.001,                # Lower learning rate
#     'warmup_epochs': 5,
#     'weight_decay': 0.0005,
#     'cls': 1.0,                  # Higher classification weight
#     'box': 7.5,
#     'single_cls': False          # Keep all classes
# }

# print("üè• MEDICAL AI TRAINING CONFIGURATION:")
# for key, value in MEDICAL_CONFIG.items():
#     print(f"   {key}: {value}")

# print(f"\n‚è±Ô∏è Expected training time: 45-60 minutes")
# print(f"üéØ Target performance: >70% mAP@0.5")

# # Load better model
# model = YOLO(MEDICAL_CONFIG['model'])

# print("üöÄ Starting MEDICAL-GRADE training...")
# start_time = datetime.now()

# # Start proper training
# results = model.train(
#     data="/content/drive/MyDrive/Dataset1yolo8coco/stenosis/data.yaml",
#     epochs=MEDICAL_CONFIG['epochs'],
#     batch=MEDICAL_CONFIG['batch'],
#     imgsz=MEDICAL_CONFIG['imgsz'],
#     device=MEDICAL_CONFIG['device'],
#     project=MEDICAL_CONFIG['project'],
#     name=MEDICAL_CONFIG['name'],
#     patience=MEDICAL_CONFIG['patience'],
#     save_period=MEDICAL_CONFIG['save_period'],
#     verbose=MEDICAL_CONFIG['verbose'],
#     plots=MEDICAL_CONFIG['plots'],
#     val=MEDICAL_CONFIG['val'],
#     cache=MEDICAL_CONFIG['cache'],
#     workers=MEDICAL_CONFIG['workers'],
#     amp=MEDICAL_CONFIG['amp'],
#     lr0=MEDICAL_CONFIG['lr0'],
#     warmup_epochs=MEDICAL_CONFIG['warmup_epochs'],
#     weight_decay=MEDICAL_CONFIG['weight_decay'],
#     cls=MEDICAL_CONFIG['cls'],
#     box=MEDICAL_CONFIG['box']
# )

# end_time = datetime.now()
# training_duration = (end_time - start_time).total_seconds() / 60

# print(f"\nüéâ MEDICAL TRAINING COMPLETED!")
# print(f"‚è±Ô∏è Training time: {training_duration:.1f} minutes")

# # Cell: Export Training Visualizations (Loss, mAP, Confusion Matrix)
# import os
# import matplotlib.pyplot as plt
# from PIL import Image
# from glob import glob

# # Set your project and experiment folder
# PROJECT_DIR = "/content/medical_stenosis"  # or "medical_stenosis"
# EXPERIMENT_NAME = "medical_training_XXXX"  # or "medical_training_XXXX"

# EXP_DIR = os.path.join(PROJECT_DIR, EXPERIMENT_NAME)
# assert os.path.exists(EXP_DIR), f"‚ùå Directory not found: {EXP_DIR}"

# # Search for standard YOLO plots
# plot_files = sorted(glob(os.path.join(EXP_DIR, "*.png")))
# print(f"üìä Found {len(plot_files)} plot(s) in {EXP_DIR}")

# # Display and optionally save all plots
# output_dir = "/content/training_plots"
# os.makedirs(output_dir, exist_ok=True)

# for pf in plot_files:
#     img = Image.open(pf)
#     plt.figure(figsize=(10, 6))
#     plt.imshow(img)
#     plt.axis('off')
#     plt.title(os.path.basename(pf))
#     plt.show()

#     # Save to exports
#     img.save(os.path.join(output_dir, os.path.basename(pf)))
#     print(f"‚úÖ Exported: {os.path.join(output_dir, os.path.basename(pf))}")

!ls /content/

# !zip -r /content/training_plots.zip /content/training_plots

# from google.colab import files
# files.download("/content/training_plots.zip")

# üß™ SESSION 3: YOLO11m TRAINING CONFIGURATION
session_name = "session3_yolo11m"
model_size = "yolov8m.pt"  # Placeholder: change to 'yolov11m.pt' if available
epochs = 150
batch_size = 8
imgsz = 640
learning_rate = 1e-4
patience = 25
cache = "disk"
augment = True
precision = "fp16"

print(f"üìå Session: {session_name}")
print(f"üì¶ Model: {model_size} | Epochs: {epochs} | Batch: {batch_size} | LR: {learning_rate}")

# üîÑ Load YOLO Model
from ultralytics import YOLO

model = YOLO(model_size)

# Optional: Resume from checkpoint if available
# model = YOLO('/content/drive/MyDrive/weights/yolov11m_pretrained.pt')

# üöÄ Train the YOLOv11m Model
results = model.train(
    data="/content/drive/MyDrive/Dataset1yolo8coco/stenosis/data.yaml",
    epochs=epochs,
    imgsz=imgsz,
    batch=batch_size,
    lr0=learning_rate,
    patience=patience,
    device=0,
    name=session_name,
    cache=cache,
    amp=precision == "fp16",
    augment=augment,
    verbose=True
)

# üìà Evaluate Model on Validation Set
metrics = model.val()
print(metrics)

# üìä Load Training Plots (mAP, loss, etc.)
import os
from PIL import Image
from glob import glob
import matplotlib.pyplot as plt

plot_dir = f"/content/runs/detect/session3_yolo11m2"
plot_files = sorted(glob(os.path.join(plot_dir, "*.png")))

for pf in plot_files:
    img = Image.open(pf)
    plt.figure(figsize=(10, 6))
    plt.imshow(img)
    plt.axis('off')
    plt.title(os.path.basename(pf))
    plt.show()

import zipfile

zip_path = "/content/yolo_training_plots.zip"
with zipfile.ZipFile(zip_path, 'w') as zipf:
    for file in plot_files:
        zipf.write(file, arcname=os.path.basename(file))

print(f"‚úÖ All plots zipped at: {zip_path}")

from google.colab import files
files.download(zip_path)